---
abstract: Practising and honing skills forms a fundamental component of how
  humans learn, yet artificial agents are rarely specifically trained to perform
  them. Instead, they are usually trained end-to-end, with the hope being that
  useful skills will be implicitly learned in order to maximise discounted
  return of some extrinsic reward function. In this paper, we investigate how
  skills can be incorporated into the training of reinforcement learning (RL)
  agents in complex environments with large state-action spaces and sparse
  rewards. To this end, we created SkillHack, a benchmark of tasks and
  associated skills based on the game of NetHack. We evaluate a number of
  baselines on this benchmark, as well as our own novel skill-based method
  Hierarchical Kickstarting (HKS), which is shown to outperform all other
  evaluated methods. Our experiments show that learning with a prior knowledge
  of useful skills can significantly improve the performance of agents on
  complex problems. We ultimately argue that utilising predefined skills
  provides a useful inductive bias for RL problems, especially those with large
  state-action spaces and sparse rewards.
slides: ""
url_pdf: https://arxiv.org/abs/2207.11584
publication_types:
  - "1"
authors:
  - admin
  - Mikayel Samvelyan
  - Jack Parker-Holder
  - Edward Grefenstette
  - Tim Rockt√§schel
author_notes: []
publication: In Conference on Lifelong Learning Agents 2022
summary: ""
url_dataset: ""
url_project: ""
publication_short: ""
url_source: ""
url_video: ""
title: Hierarchical Kickstarting for Skill Transfer in Reinforcement Learning
doi: ""
featured: false
tags: []
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: false
date: 2022-07-23T18:37:16.642Z
url_slides: ""
publishDate: 2017-01-01T00:00:00.000Z
url_poster: ""
url_code: ""
---
